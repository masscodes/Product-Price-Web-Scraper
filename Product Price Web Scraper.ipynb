{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7365c4eb",
   "metadata": {},
   "source": [
    "# Product Price Web Scraper\n",
    "\n",
    "\n",
    "\n",
    "## 1. Challenge\n",
    "\n",
    "One of the e-commerce stores needed to verify product prices against competitors to boost sales. A list of websites containing product prices was created, and the goal was to fetch and compile this data into a report. The report should refresh every 24 hours.\n",
    "\n",
    "\n",
    "## 2. Idea\n",
    "\n",
    "Initially, simpler solutions were considered. Google Spreadsheets offers the importXML function, but unfortunately, it doesn't work well with Single Page Application websites. Attempts were made using the requests library, but most websites detected these requests as bot activities, even after changing headers (via Cloudflare). The next step involved using the Selenium library, which emulates a browser. The script worked locally, but issues arose when deployed on PythonAnywhere. Adding the headless option resulted in no browser window emulation, triggering Cloudflare to classify the activity as bot-like. Despite using the undetected chromedriver library, the problem persisted. The plan was to publish the report in HTML format.\n",
    "\n",
    "\n",
    "## 3. Conclusion\n",
    "\n",
    "The project was closed due to the implementation of an alternative solution.\n",
    "\n",
    "\n",
    "## 4. Possible Improvements\n",
    "\n",
    "The primary focus should be on resolving the issue of Cloudflare classifying the request as bot-like, as it leads to content blocking. Automatic updating of the list of URLs containing the required products is also necessary. Additionally, changing CSS selectors may pose a potential problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from functions import *\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "\n",
    "\n",
    "def getUrls(file):\n",
    "\n",
    "    data = []\n",
    "    with open(file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "\n",
    "def writeData(data, fileName):\n",
    "    with open(fileName, mode='w') as writer:\n",
    "\n",
    "        writer.writelines('<!DOCTYPE html><html lang=\"en\"><head><title>Report</title></head><body><table cellspacing=\"0\" cellpadding=\"0\">\\n')\n",
    "        for row in data:\n",
    "            codeS = \"<tr>\"\n",
    "\n",
    "            for cell in row:\n",
    "\n",
    "                codeS = codeS + '<td align=\"center\" width=\"400\" style=\"border: 1px solid #000000; padding-top:10px; padding-bottom:10px\">' + cell + '</td>'\n",
    "\n",
    "            codeS = codeS + \"</tr>\\n\"\n",
    "\n",
    "            writer.write(codeS)\n",
    "\n",
    "        writer.writelines('</table></body></html>')\n",
    "        \n",
    "        \n",
    "def main():\n",
    "\n",
    "    urls = getUrls('urlist.csv')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    selectors = {\n",
    "        'site_x': 'css_selector',\n",
    "        'site_y': 'css_selector',\n",
    "        'site_z': 'css_selector',\n",
    "    }\n",
    "    \n",
    "    for url in urls:\n",
    "    \n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(url)\n",
    "    \n",
    "        for site in selectors:\n",
    "            if site in url:\n",
    "                try:\n",
    "                    data.append(driver.find_element(By.CSS_SELECTOR, selectors[site]).get_attribute(\"innerHTML\"))\n",
    "    \n",
    "                except NoSuchElementException as e:\n",
    "                    print(e)\n",
    "    \n",
    "        time.sleep(2)\n",
    "        driver.close()\n",
    "    \n",
    "    writeData(data, 'index.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
